{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import diffusers\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from pipeline import (\n",
    "    DNAEditFluxPipeline,\n",
    "    FireFlowEditFluxPipeline,\n",
    "    FlowEditFluxPipeline,\n",
    "    FTEditFluxPipeline,\n",
    "    MultiTurnEditFluxPipeline,\n",
    "    RFInversionEditFluxPipeline,\n",
    "    RFSolverEditFluxPipeline,\n",
    ")\n",
    "from processor.ft_editing_attn_processor import FluxAttentionReplace, P2PFlux_JointAttnProcessor2_0\n",
    "\n",
    "diffusers.utils.logging.set_verbosity_error()\n",
    "\n",
    "prompt_sequence = [\n",
    "    {\n",
    "        \"prompt\": \"a round cake with frosting on a wooden plate\",\n",
    "        \"editing_type_id\": \"0\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with frosting on a wooden plate\",\n",
    "        \"editing_type_id\": \"6\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with frosting and chocolate sprinkles on a wooden plate\",\n",
    "        \"editing_type_id\": \"6\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with with frosting, chocolate sprinkles, and strawberry slices on a wooden plate\",\n",
    "        \"editing_type_id\": \"4\",\n",
    "    },\n",
    "]\n",
    "prompt_sequence = [prompt[\"prompt\"] for prompt in prompt_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45cb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_concat_pil_images(images):\n",
    "    widths, heights = zip(*(i.size for i in images), strict=True)\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_image = Image.new(\"RGB\", (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        new_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca312089",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pipe = [\n",
    "    (\"RFInversion\", RFInversionEditFluxPipeline, 28),\n",
    "    (\"RFSolver\", RFSolverEditFluxPipeline, 28),\n",
    "    (\"FireFlow\", FireFlowEditFluxPipeline, 28),\n",
    "    (\"FlowEdit\", FlowEditFluxPipeline, 28),\n",
    "    (\"FTEdit\", FTEditFluxPipeline, 28),\n",
    "    (\"DNAEdit\", DNAEditFluxPipeline, 28),\n",
    "    (\"MultiTurn\", MultiTurnEditFluxPipeline, 28),\n",
    "]\n",
    "\n",
    "source_img = \"assets/sources/cake.jpg\"\n",
    "source_prompt = \"a round cake with frosting on a wooden plate besides a cup\"\n",
    "\n",
    "for pipe_name, pipe, num_inference_steps in target_pipe:\n",
    "    print(f\"Running {pipe_name}...\")\n",
    "    pipe = pipe.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
    "    pipe.to(\"cuda\")\n",
    "    pipe.set_progress_bar_config(disable=True)\n",
    "\n",
    "    if pipe_name in [\"RFSolver\", \"FireFlow\"]:\n",
    "        pipe.add_processor(after_layer=0, filter_name=\"single_transformer_blocks\")\n",
    "    elif pipe_name == \"MultiTurn\":\n",
    "        pipe.add_processor(\n",
    "            after_layer=0, before_layer=37, filter_name=[\"single_transformer_blocks\", \"transformer_blocks\"]\n",
    "        )\n",
    "    elif pipe_name == \"FTEdit\":\n",
    "        controller = FluxAttentionReplace(\n",
    "            prompts=[\"\", \"\"],  # dummy prompts\n",
    "            num_steps=num_inference_steps,\n",
    "            attn_ratio=0.15,\n",
    "            num_att_layers=37,\n",
    "        )\n",
    "        pipe.add_processor(\n",
    "            after_layer=0,\n",
    "            before_layer=36,\n",
    "            filter_name=\"transformer_blocks\",\n",
    "            target_processor=P2PFlux_JointAttnProcessor2_0,\n",
    "            controller=controller,\n",
    "        )\n",
    "\n",
    "    kwargs = {}\n",
    "    if pipe_name == \"RFInversion\":\n",
    "        kwargs[\"stop_timestep\"] = 0.25\n",
    "        kwargs[\"guidance_scale\"] = 3.5\n",
    "    elif pipe_name == \"RFSolver\":\n",
    "        kwargs[\"with_second_order\"] = True\n",
    "        kwargs[\"inject_step\"] = 3\n",
    "        kwargs[\"guidance_scale\"] = 2\n",
    "    elif pipe_name == \"FireFlow\":\n",
    "        kwargs[\"inject_step\"] = 3\n",
    "        kwargs[\"with_second_order\"] = True\n",
    "        kwargs[\"guidance_scale\"] = 2\n",
    "    elif pipe_name == \"MultiTurn\":\n",
    "        kwargs[\"stop_timestep\"] = 0.25\n",
    "        kwargs[\"with_second_order\"] = True\n",
    "        kwargs[\"inject_step\"] = 0\n",
    "        kwargs[\"attn_guidance_start_block\"] = 11\n",
    "        kwargs[\"guidance_scale\"] = 3.5\n",
    "    elif pipe_name == \"FlowEdit\":\n",
    "        kwargs[\"interpolate_start_step\"] = 0\n",
    "        kwargs[\"interpolate_end_step\"] = 24\n",
    "        kwargs[\"source_guidance_scale\"] = 1.5\n",
    "        kwargs[\"target_guidance_scale\"] = 5.5\n",
    "    elif pipe_name == \"FTEdit\":\n",
    "        kwargs[\"fixed_point_steps\"] = 3\n",
    "        kwargs[\"ly_ratio\"] = 1.0\n",
    "        kwargs[\"guidance_scale\"] = 2\n",
    "    elif pipe_name == \"DNAEdit\":\n",
    "        kwargs[\"start_timestep\"] = 4\n",
    "        kwargs[\"source_guidance_scale\"] = 1\n",
    "        kwargs[\"target_guidance_scale\"] = 2.5\n",
    "\n",
    "    image_list = pipe.multiturn(\n",
    "        source_img,\n",
    "        source_prompt,\n",
    "        prompt_sequence,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        **kwargs,\n",
    "    )\n",
    "    image_list = [Image.open(source_img)] + image_list\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for image_idx, image in enumerate(image_list):\n",
    "        plt.subplot(1, len(image_list), image_idx + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    concat_image = h_concat_pil_images(image_list[1:])\n",
    "    concat_image.save(f\"assets/images/multi_turn_for_each_step_28_better/{pipe_name}.jpg\")\n",
    "    \n",
    "    del pipe\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf4a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
