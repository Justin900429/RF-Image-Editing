{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eaf3ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/justin/RF-Solver-Edit-Diffusers/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import diffusers\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from pipeline import (\n",
    "    FireFlowEditFluxPipeline,\n",
    "    FlowEditFluxPipeline,\n",
    "    FTEditFluxPipeline,\n",
    "    MultiTurnEditFluxPipeline,\n",
    "    RFInversionEditFluxPipeline,\n",
    "    RFSolverEditFluxPipeline,\n",
    ")\n",
    "from processor.ft_editing_attn_processor import FluxAttentionReplace, P2PFlux_JointAttnProcessor2_0\n",
    "\n",
    "diffusers.utils.logging.set_verbosity_error()\n",
    "\n",
    "prompt_sequence = [\n",
    "    {\n",
    "        \"prompt\": \"a square cake with orange frosting on a wooden plate\", \n",
    "        \"editing_type_id\": \"0\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with orange frosting on a glass plate\",\n",
    "        \"editing_type_id\": \"7\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with orange frosting and chocolate sprinkles on a glass plate\",\n",
    "        \"editing_type_id\": \"2\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with green frosting and chocolate sprinkles on a glass plate\",\n",
    "        \"editing_type_id\": \"6\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with green frosting and chocolate sprinkles on a marble plate\",\n",
    "        \"editing_type_id\": \"7\",\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"a square cake with green frosting and strawberry slices on a marble plate\",\n",
    "        \"editing_type_id\": \"4\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca312089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RFInversion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 69.66it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 31.73it/s]it/s]\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.86it/s]\n"
     ]
    }
   ],
   "source": [
    "target_pipe = [\n",
    "    (\"RFInversion\", RFInversionEditFluxPipeline, 15),\n",
    "    (\"RFSolver\", RFSolverEditFluxPipeline, 15),\n",
    "    (\"FireFlow\", FireFlowEditFluxPipeline, 15),\n",
    "    (\"FlowEdit\", FlowEditFluxPipeline, 15),\n",
    "    (\"FTEdit\", FTEditFluxPipeline, 15),\n",
    "    (\"MultiTurn\", MultiTurnEditFluxPipeline, 15),\n",
    "    \n",
    "]\n",
    "\n",
    "prompt_sequence = [prompt[\"prompt\"] for prompt in prompt_sequence]\n",
    "source_img = \"data/PIE-Bench_v1/annotation_images/0_random_140/000000000001.jpg\"\n",
    "source_prompt = \"a round cake with orange frosting on a wooden plate\"\n",
    "\n",
    "for pipe_name, pipe, num_inference_steps in target_pipe:\n",
    "    print(f\"Running {pipe_name}...\")\n",
    "    pipe = pipe.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
    "    pipe.to(\"cuda\")\n",
    "    pipe.set_progress_bar_config(disable=True)\n",
    "    \n",
    "    if pipe_name in [\"RFSolver\", \"FireFlow\"]:\n",
    "        pipe.add_processor(after_layer=0, before_layer=37, filter_name=\"single_transformer_blocks\")\n",
    "    elif pipe_name == \"MultiTurn\":\n",
    "        pipe.add_processor(after_layer=0, before_layer=37, filter_name=[\"single_transformer_blocks\", \"transformer_blocks\"])\n",
    "    elif pipe_name == \"FTEdit\":\n",
    "        controller = FluxAttentionReplace(\n",
    "            prompts=[\"\", \"\"],  # dummy prompts\n",
    "            num_steps=num_inference_steps,\n",
    "            attn_ratio=0.15,\n",
    "            num_att_layers=37,\n",
    "        )\n",
    "        pipe.add_processor(after_layer=37, before_layer=0, filter_name=\"transformer_blocks\", target_processor=P2PFlux_JointAttnProcessor2_0, controller=controller)\n",
    "\n",
    "    kwargs = {\"guidance_scale\": 3.5}\n",
    "    if pipe_name == \"RFInversion\":\n",
    "        kwargs[\"stop_timestep\"] = 0.25\n",
    "    elif pipe_name in [\"RFSolver\", \"FireFlow\"]:\n",
    "        kwargs[\"with_second_order\"] = True\n",
    "        kwargs[\"inject_step\"] = 2\n",
    "    elif pipe_name == \"MultiTurn\":\n",
    "        kwargs[\"stop_timestep\"] = 0.25\n",
    "        kwargs[\"with_second_order\"] = True\n",
    "        kwargs[\"inject_step\"] = 0\n",
    "        kwargs[\"attn_guidance_start_block\"] = 11\n",
    "    elif pipe_name == \"FlowEdit\":\n",
    "        del kwargs[\"guidance_scale\"]\n",
    "        kwargs[\"interpolate_start_step\"] = 0\n",
    "        kwargs[\"interpolate_end_step\"] = 15\n",
    "        kwargs[\"source_guidance_scale\"] = 1.5\n",
    "        kwargs[\"target_guidance_scale\"] = 5.5\n",
    "    elif pipe_name == \"FTEdit\":\n",
    "        kwargs[\"fixed_point_steps\"] = 3\n",
    "        kwargs[\"ly_ratio\"] = 1.0\n",
    "\n",
    "    image_list = pipe.multiturn(\n",
    "        source_img,\n",
    "        source_prompt,\n",
    "        prompt_sequence,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        **kwargs,\n",
    "    )\n",
    "    image_list = [Image.open(source_img)] + image_list\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for image_idx, image in enumerate(image_list):\n",
    "        plt.subplot(1, len(image_list), image_idx + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "        \n",
    "    del pipe\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf4a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
